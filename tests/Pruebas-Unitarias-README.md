# Pruebas Unitarias - AplicaciÃ³n de ClasificaciÃ³n de Comentarios

Este directorio contiene las pruebas unitarias para la aplicaciÃ³n de Streamlit que clasifica comentarios de negocios en Detractores, Promotores y Neutros.

## ğŸ“ Estructura de Pruebas

```
tests/
â”œâ”€â”€ test_streamlit_app.py          # Pruebas principales de la aplicaciÃ³n
â”œâ”€â”€ test_streamlit_components.py   # Pruebas de componentes especÃ­ficos
â”œâ”€â”€ test_almacenamiento.py         # Pruebas existentes de almacenamiento
â”œâ”€â”€ test_analisis_evaluacion.py   # Pruebas existentes de anÃ¡lisis
â””â”€â”€ Pruebas-Unitarias-README.md                 # Este archivo
```

## ğŸ§ª Archivos de Prueba

### `test_streamlit_app.py`
Pruebas principales de la aplicaciÃ³n Streamlit:
- âœ… Carga correcta de la aplicaciÃ³n
- âœ… Existencia de componentes UI (tÃ­tulos, sidebar, etc.)
- âœ… Funcionalidad del file uploader
- âœ… Manejo de session_state
- âœ… VisualizaciÃ³n de anÃ¡lisis cargados
- âœ… Interacciones con botones y selectbox

**Clases de prueba:**
- `TestStreamlitApp`: Pruebas bÃ¡sicas de la aplicaciÃ³n
- `TestAppWithMockedData`: Pruebas con datos simulados
- `TestAppComponents`: Pruebas de componentes importados
- `TestAppInteractions`: Pruebas de interacciones de usuario
- `TestAppIntegration`: Pruebas de integraciÃ³n completa

### `test_streamlit_components.py`
Pruebas de componentes especÃ­ficos:
- âœ… Funciones de layout (show_header, show_tables, upload_file_view)
- âœ… Funciones del controlador (get_services, process_uploaded_file)
- âœ… Procesamiento de archivos CSV
- âœ… Manejo de session_state
- âœ… VisualizaciÃ³n de clasificaciones
- âœ… Manejo de errores

**Clases de prueba:**
- `TestLayoutComponents`: Componentes de presentaciÃ³n
- `TestLoaderFunctions`: Funciones del cargador
- `TestSessionStateManagement`: GestiÃ³n del estado
- `TestAnalysisDisplay`: VisualizaciÃ³n de anÃ¡lisis
- `TestButtonInteractions`: Interacciones con botones
- `TestSelectboxInteraction`: Interacciones con selectbox
- `TestErrorHandling`: Manejo de errores

## ğŸš€ CÃ³mo Ejecutar las Pruebas

### 1. Activar el Entorno Virtual

```fish
source ./Py/bin/activate
```

### 2. Ejecutar Todas las Pruebas

```fish
# Todas las pruebas de Streamlit
pytest tests/test_streamlit_app.py tests/test_streamlit_components.py -v

# Solo pruebas principales
pytest tests/test_streamlit_app.py -v

# Solo pruebas de componentes
pytest tests/test_streamlit_components.py -v
```

### 3. Ejecutar Pruebas EspecÃ­ficas

```fish
# Una clase de pruebas especÃ­fica
pytest tests/test_streamlit_app.py::TestStreamlitApp -v

# Una prueba especÃ­fica
pytest tests/test_streamlit_app.py::TestStreamlitApp::test_app_loads_successfully -v
```

### 4. Ejecutar con Cobertura

```fish
# Generar reporte de cobertura
pytest tests/test_streamlit_app.py tests/test_streamlit_components.py --cov=src/main --cov-report=html

# Ver reporte en el navegador
# El reporte se genera en htmlcov/index.html
```

### 5. Ejecutar con Diferentes Niveles de Verbosidad

```fish
# Modo silencioso (solo resultados)
pytest tests/test_streamlit_app.py -q

# Modo normal
pytest tests/test_streamlit_app.py

# Modo verbose (muestra cada test)
pytest tests/test_streamlit_app.py -v

# Modo muy verbose (muestra detalles completos)
pytest tests/test_streamlit_app.py -vv
```

## ğŸ“Š Opciones Ãštiles de Pytest

```fish
# Detener en el primer fallo
pytest tests/test_streamlit_app.py -x

# Mostrar variables locales en errores
pytest tests/test_streamlit_app.py -l

# Mostrar print statements
pytest tests/test_streamlit_app.py -s

# Ejecutar solo tests que fallaron la Ãºltima vez
pytest tests/test_streamlit_app.py --lf

# Ejecutar tests en paralelo (requiere pytest-xdist)
pytest tests/test_streamlit_app.py -n auto
```

## ğŸ”§ ConfiguraciÃ³n

Las pruebas utilizan la configuraciÃ³n definida en `pytest.ini`:

```ini
[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
```

## ğŸ“ Notas Importantes

### Limitaciones Conocidas

1. **Modelo de ML**: Algunas pruebas pueden fallar si el archivo del modelo (`clasificador_sentimiento_final.pkl`) no existe. Estas pruebas se saltarÃ¡n automÃ¡ticamente con `pytest.skip()`.

2. **Base de Datos**: Las pruebas que interactÃºan con la base de datos pueden requerir configuraciÃ³n adicional o datos de prueba.

3. **File Upload**: La funcionalidad completa de carga de archivos tiene limitaciones en el entorno de testing de Streamlit.

### Pruebas que Pueden Requerir Datos Externos

- `test_get_services_function`: Requiere el modelo ML
- `test_sidebar_analysis_list`: Depende de anÃ¡lisis guardados en BD
- `test_file_uploader_accepts_csv`: Requiere procesamiento completo

### Datos de Prueba

Los tests crean datos de ejemplo internamente:

```python
sample_data = pd.DataFrame({
    'Calificacion': [5, 4, 3, 2, 1],
    'Comentarios': [
        'Excelente servicio',
        'Buen producto',
        'Normal',
        'Malo',
        'PÃ©simo'
    ]
})
```

## ğŸ› DepuraciÃ³n de Pruebas

### Ver trazas completas de errores

```fish
pytest tests/test_streamlit_app.py --tb=long
```

### Usar debugger en una prueba

```python
def test_example(self, app):
    import pdb; pdb.set_trace()
    app.run()
    assert not app.exception
```

### Ver warnings

```fish
pytest tests/test_streamlit_app.py -W all
```

## ğŸ“ˆ Mejores PrÃ¡cticas

1. **Ejecutar pruebas antes de commit**: AsegÃºrate de que todas las pruebas pasen antes de hacer commit.

2. **Mantener pruebas aisladas**: Cada prueba debe ser independiente y no depender del estado de otras.

3. **Usar fixtures**: Reutiliza configuraciÃ³n comÃºn a travÃ©s de fixtures de pytest.

4. **Nombres descriptivos**: Los nombres de las pruebas deben describir claramente quÃ© estÃ¡n probando.

5. **DocumentaciÃ³n**: Documenta pruebas complejas con docstrings.

## ğŸ”„ IntegraciÃ³n Continua

Estas pruebas pueden integrarse en un pipeline CI/CD:

```yaml
# Ejemplo para GitHub Actions
name: Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.13'
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      - name: Run tests
        run: |
          pytest tests/test_streamlit_app.py tests/test_streamlit_components.py -v
```

## ğŸ“š Recursos Adicionales

- [DocumentaciÃ³n oficial de Streamlit Testing](https://docs.streamlit.io/develop/api-reference/app-testing)
- [DocumentaciÃ³n de Pytest](https://docs.pytest.org/)
- [AppTest API Reference](https://docs.streamlit.io/develop/api-reference/app-testing/st.testing.v1.apptest)

## ğŸ†˜ SoluciÃ³n de Problemas

### Error: "No module named 'streamlit.testing'"

AsegÃºrate de tener Streamlit 1.18.0 o superior:

```fish
pip install --upgrade streamlit
```

### Error: "AppTest timeout"

Aumenta el timeout en el fixture:

```python
at = AppTest.from_file(app_path, default_timeout=30)
```

### Error: "FileNotFoundError: modelo no encontrado"

Algunas pruebas se saltarÃ¡n automÃ¡ticamente. Esto es esperado si no tienes el modelo entrenado.

---

**Ãšltima actualizaciÃ³n**: Noviembre 2025
**VersiÃ³n de Streamlit requerida**: 1.50.0+
**VersiÃ³n de Python**: 3.13+
